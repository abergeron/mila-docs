

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Singularity &mdash; MILA Docs latest documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  
    <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="MILA Docs latest documentation" href="../index.html"/>
        <link rel="prev" title="Docker/Shifter" href="../docker/index.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> MILA Docs
          

          
          </a>

          
            
            
              <div class="version">
                latest
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cluster_intro.html">What is a computer Cluster ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cluster_intro.html#resources-available-at-mila">Resources Available at Mila</a></li>
</ul>
<p class="caption"><span class="caption-text">The batch scheduler: Slurm</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../slurm/index.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../slurm/index.html#basic-usage">Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../slurm/advanced.html">Advanced Usage</a></li>
</ul>
<p class="caption"><span class="caption-text">Computing Clusters</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mila-cluster/index.html">Mila Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compute-canada-cluster/index.html">Compute Canada Clusters</a></li>
</ul>
<p class="caption"><span class="caption-text">Software</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../software/index.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/python.html">Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/tools.html">Tools</a></li>
</ul>
<p class="caption"><span class="caption-text">Containers</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../docker/index.html">Docker/Shifter</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Singularity</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#why-should-you-use-containers">Why should you use containers ?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#building-containers">Building containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#first-way-build-and-use-a-sandbox">First way: Build and use a sandbox</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#on-which-machine-should-i-build-a-container">On which machine should I build a container ?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#download-containers-from-the-web">Download containers from the web</a></li>
<li class="toctree-l4"><a class="reference internal" href="#how-to-add-or-install-stuff-in-a-container">How to add or install stuff in a container</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#second-way-use-recipes">Second way: Use recipes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#singularity-recipe">Singularity Recipe</a></li>
<li class="toctree-l4"><a class="reference internal" href="#build-recipe-on-singularity-hub">Build recipe on singularity hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-recipe-with-openai-gym-mujoco-and-miniworld">Example: Recipe with openai gym, mujoco and miniworld</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#using-containers-on-clusters">Using containers on clusters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-interactive-case-srun-salloc">Example: Interactive case (srun/salloc)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-sbatch-case">Example: sbatch case</a></li>
<li class="toctree-l3"><a class="reference internal" href="#issue-with-pybullet-and-opengl-libraries">Issue with PyBullet and OpenGL libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">Mila cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mila-cloud-cluster">Mila-cloud cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compute-canada">Compute Canada</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MILA Docs</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Singularity</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/mila-iqia/mila-docs/blob/master/docs/singularity/index.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <p>Reproducible.. _singularity:</p>
<div class="section" id="singularity">
<h1>Singularity<a class="headerlink" href="#singularity" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="mila-cluster">
<p class="topic-title">Mila Cluster</p>
<ul class="simple">
<li><p><a class="reference internal" href="#why-should-you-use-containers" id="id4">Why should you use containers ?</a></p></li>
<li><p><a class="reference internal" href="#building-containers" id="id5">Building containers</a></p>
<ul>
<li><p><a class="reference internal" href="#first-way-build-and-use-a-sandbox" id="id6">First way: Build and use a sandbox</a></p></li>
<li><p><a class="reference internal" href="#second-way-use-recipes" id="id7">Second way: Use recipes</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#using-containers-on-clusters" id="id8">Using containers on clusters</a></p>
<ul>
<li><p><a class="reference internal" href="#example-interactive-case-srun-salloc" id="id9">Example: Interactive case (srun/salloc)</a></p></li>
<li><p><a class="reference internal" href="#example-sbatch-case" id="id10">Example: sbatch case</a></p></li>
<li><p><a class="reference internal" href="#issue-with-pybullet-and-opengl-libraries" id="id11">Issue with PyBullet and OpenGL libraries</a></p></li>
<li><p><a class="reference internal" href="#id3" id="id12">Mila cluster</a></p></li>
<li><p><a class="reference internal" href="#mila-cloud-cluster" id="id13">Mila-cloud cluster</a></p></li>
<li><p><a class="reference internal" href="#compute-canada" id="id14">Compute Canada</a></p></li>
</ul>
</li>
</ul>
</div>
<p>Singularity is a software container system designed to facilitate portability and reproducibility of high performance computing (HPC) workflows.
It performs a function similar to docker, but with HPC in mind. It is compatible with existing docker containers, and provides tools for
building new containers from recipe files or ad-hoc commands.</p>
<div class="section" id="why-should-you-use-containers">
<h2><a class="toc-backref" href="#id4">Why should you use containers ?</a><a class="headerlink" href="#why-should-you-use-containers" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 85%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Advantages</p></th>
<th class="head"><p>Descriptions</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Reproducibility</p></td>
<td><p>All software you have used for your experiments is packaged inside one file.</p></td>
</tr>
<tr class="row-odd"><td><p>Portability</p></td>
<td><p>Copy the container you built on every cluster without the need to install anything.</p></td>
</tr>
<tr class="row-even"><td><p>Flexibility</p></td>
<td><p>You can use apt-get !</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="building-containers">
<h2><a class="toc-backref" href="#id5">Building containers</a><a class="headerlink" href="#building-containers" title="Permalink to this headline">¶</a></h2>
<p>Building a container is like creating a new environment except that containers are much more powerful since they are self-contain systems.
With singularity, there are two ways to build containers.</p>
<p>The first one is by yourself, it’s like when you got a new Linux laptop and you don’t really know what you need, if you see that something is missing,
you install it. Here you can get a vanilla container with Ubuntu called a sandbox, you log in and you install each packages by yourself.
This procedure can take time but will allow you to understand how things work and what you need. This is recommended if you need to figure out
how things will be compiled or if you want to install packages on the fly. We’ll refer to this procedure as singularity sandboxes.</p>
<p>The second one way is more like you know what you want, so you write a list of everything you need, you sent it to singularity and it will install
everything for you. Those lists are called singularity recipes.</p>
<div class="section" id="first-way-build-and-use-a-sandbox">
<h3><a class="toc-backref" href="#id6">First way: Build and use a sandbox</a><a class="headerlink" href="#first-way-build-and-use-a-sandbox" title="Permalink to this headline">¶</a></h3>
<div class="section" id="on-which-machine-should-i-build-a-container">
<h4>On which machine should I build a container ?<a class="headerlink" href="#on-which-machine-should-i-build-a-container" title="Permalink to this headline">¶</a></h4>
<p>First of all, you need to choose where you’ll build your container. This operation requires <strong>memory and high cpu usage</strong>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Do NOT build containers on any login nodes !</p>
</div>
<ul>
<li><p>(Recommended for beginner) If you need to <strong>use apt-get</strong>, you should <strong>build the container on your laptop</strong> with sudo privileges. You’ll only need to install singularity on your laptop. Windows/Mac users can look <a class="reference external" href="https://www.sylabs.io/guides/3.0/user-guide/installation.html#install-on-windows-or-mac">there</a> and Ubuntu/Debian users can use directly:</p>
<blockquote>
<div><div class="highlight-default notranslate"><div class="highlight"><pre><style type="text/css">
span.prompt1:before {
  content: "$ ";
}
</style><span class="prompt1">sudo apt-get install singularity-container</span>
</pre></div></div></div></blockquote>
</li>
<li><p>If you <strong>can’t install singularity</strong> on your laptop and you <strong>don’t need apt-get</strong>, you can reserve a <strong>cpu node on the mila cluster</strong> to build your container.</p></li>
</ul>
<p>In this case, in order to avoid too much I/O over the network, you should define the singularity cache locally:</p>
<blockquote>
<div><div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1"><span class="nb">export</span> <span class="nv">SINGULARITY_CACHEDIR</span><span class="o">=</span><span class="nv">$SLURM_TMPDIR</span></span>
</pre></div></div></div></blockquote>
<ul class="simple">
<li><p>If you <strong>can’t install singularity</strong> on your laptop and you <strong>want to use apt-get</strong>, you can use <a class="reference external" href="https://www.singularity-hub.org/">singularity-hub</a> to build your containers and read <a class="reference internal" href="#recipe-section">Recipe_section</a>.</p></li>
</ul>
</div>
<div class="section" id="download-containers-from-the-web">
<h4>Download containers from the web<a class="headerlink" href="#download-containers-from-the-web" title="Permalink to this headline">¶</a></h4>
<p>Hopefully, you may not need to create containers from scratch as many have been already built for the most common deep learning software.
You can find most of them on <a class="reference external" href="https://hub.docker.com/">dockerhub</a>.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>(Optional) You can also pull containers from nvidia cloud see <a class="reference internal" href="nvidia.html#nvidia"><span class="std std-ref">Containers from Nvidia cloud</span></a></p>
</div>
<p>Go on <a class="reference external" href="https://hub.docker.com/">dockerhub</a> and select the container you want to pull.</p>
<p>For example, if you want to get the latest pytorch version with gpu support (Replace <em>runtime</em> by <em>devel</em> if you need the full CUDA toolkit):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">singularity pull docker://pytorch/pytorch:1.0.1-cuda10.0-cudnn7-runtime</span>
</pre></div></div><p>or the latest tensorflow:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">singularity pull docker://tensorflow/tensorflow:latest-gpu-py3</span>
</pre></div></div><p>Currently the pulled image <code class="docutils literal notranslate"><span class="pre">pytorch.simg</span></code> or <code class="docutils literal notranslate"><span class="pre">tensorflow.simg</span></code> is read only meaning that you won’t be able to install anything on it.
Starting now, pytorch will be taken as example. If you use tensorflow, simply replace every <strong>pytorch</strong> occurrences by <strong>tensorflow</strong>.</p>
</div>
<div class="section" id="how-to-add-or-install-stuff-in-a-container">
<h4>How to add or install stuff in a container<a class="headerlink" href="#how-to-add-or-install-stuff-in-a-container" title="Permalink to this headline">¶</a></h4>
<p>The first step is to transform your read only container <code class="docutils literal notranslate"><span class="pre">pytorch-1.0.1-cuda10.0-cudnn7-runtime.simg</span></code> in a writable version that will allow you to add packages.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Depending of the version of singularity you are using, singularity will build a container with the extension .simg or .sif. If you got .sif files, replace every occurences of .simg by .sif.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you want to use <strong>apt-get</strong> you have to put <strong>sudo</strong> ahead of the following commands</p>
</div>
<p>This command will create a writable image in the folder <code class="docutils literal notranslate"><span class="pre">pytorch</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">singularity build --sandbox pytorch pytorch-1.0.1-cuda10.0-cudnn7-runtime.simg</span>
</pre></div></div><p>Then you’ll need the following command to log inside the container.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">singularity shell --writable -H <span class="nv">$HOME</span>:/home pytorch</span>
</pre></div></div><p>Once you get into the container, you can use pip and install anything you need (Or with <code class="docutils literal notranslate"><span class="pre">apt-get</span></code> if you built the container with sudo).</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Singularity mount your home, so if you install things into the $HOME of your container, they will be installed in your real $HOME !</p>
</div>
<p>You should install your stuff in /usr/local instead.</p>
<div class="section" id="creating-useful-directory">
<h5>Creating useful directory<a class="headerlink" href="#creating-useful-directory" title="Permalink to this headline">¶</a></h5>
<p>One of the benefit of containers is that you’ll be able to use them across different clusters. However for each cluster the dataset and experiment folder location
can be different. In order to be invariant to those locations, we will create some useful mount points inside the container:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><style type="text/css">
span.prompt2:before {
  content: "<Singularity_container>$ ";
}
</style><span class="prompt2">mkdir /dataset</span>
<span class="prompt2">mkdir /tmp_log</span>
<span class="prompt2">mkdir /final_log</span>
</pre></div></div><p>From now, you won’t need to worry anymore when you write your code to specify where to pick up your dataset. Your dataset will always be in <code class="docutils literal notranslate"><span class="pre">/dataset</span></code>
independently of the cluster you are using.</p>
</div>
<div class="section" id="testing">
<h5>Testing<a class="headerlink" href="#testing" title="Permalink to this headline">¶</a></h5>
<p>If you have some code that you want to test before finalizing your container, you have two choices.
You can either log into your container and run python code inside it with</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">singularity shell --nv pytorch</span>
</pre></div></div><p>or you can execute your command directly with</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">singularity <span class="nb">exec</span> --nv pytorch python YOUR_CODE.py</span>
</pre></div></div><div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>—nv allows the container to use gpus. You don’t need this if you don’t plan to use a gpu.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Don’t forget to clear the cache of the packages you installed in the containers.</p>
</div>
</div>
<div class="section" id="creating-a-new-image-from-the-sandbox">
<h5>Creating a new image from the sandbox<a class="headerlink" href="#creating-a-new-image-from-the-sandbox" title="Permalink to this headline">¶</a></h5>
<p>Once everything you need is installed inside the container, you need to convert it back to a read-only singularity image with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">singularity build pytorch_final.simg pytorch</span>
</pre></div></div></div>
</div>
</div>
<div class="section" id="second-way-use-recipes">
<span id="recipe-section"></span><h3><a class="toc-backref" href="#id7">Second way: Use recipes</a><a class="headerlink" href="#second-way-use-recipes" title="Permalink to this headline">¶</a></h3>
<div class="section" id="singularity-recipe">
<h4>Singularity Recipe<a class="headerlink" href="#singularity-recipe" title="Permalink to this headline">¶</a></h4>
<p>A singularity recipe is a file including specifics about installation software, environment variables, files to add, and container metadata.
It is a starting point for designing any custom container. Instead of pulling a container and install your packages manually, you can specify
in this file the packages you want and then build your container from this file.</p>
<p>Here is a toy example of a singularity recipe installing some stuff:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">################# Header: Define the base system you want to use ################</span>
<span class="c1"># Reference of the kind of base you want to use (e.g., docker, debootstrap, shub).</span>
Bootstrap: docker
<span class="c1"># Select the docker image you want to use (Here we choose tensorflow)</span>
From: tensorflow/tensorflow:latest-gpu-py3

<span class="c1">################# Section: Defining the system #################################</span>
<span class="c1"># Commands in the %post section are executed within the container.</span>
%post
        <span class="nb">echo</span> <span class="s2">&quot;Installing Tools with apt-get&quot;</span>
        apt-get update
        apt-get install -y cmake libcupti-dev libyaml-dev wget unzip
        apt-get clean
        <span class="nb">echo</span> <span class="s2">&quot;Installing things with pip&quot;</span>
        pip install tqdm
        <span class="nb">echo</span> <span class="s2">&quot;Creating mount points&quot;</span>
        mkdir /dataset
        mkdir /tmp_log
        mkdir /final_log


<span class="c1"># Environment variables that should be sourced at runtime.</span>
%environment
        <span class="c1"># use bash as default shell</span>
        <span class="nv">SHELL</span><span class="o">=</span>/bin/bash
        <span class="nb">export</span> SHELL
</pre></div>
</div>
<p>A recipe file contains two parts: the <code class="docutils literal notranslate"><span class="pre">header</span></code> and <code class="docutils literal notranslate"><span class="pre">sections</span></code>. In the <code class="docutils literal notranslate"><span class="pre">header</span></code> you specify which base system you want to
use, it can be any docker or singularity container. In <code class="docutils literal notranslate"><span class="pre">sections</span></code>, you can list the things you want to install in the subsection
<code class="docutils literal notranslate"><span class="pre">post</span></code> or list the environment’s variable you need to source at each runtime in the subsection <code class="docutils literal notranslate"><span class="pre">environment</span></code>. For a more detailed
description, please look at the <a class="reference external" href="https://www.sylabs.io/guides/2.6/user-guide/container_recipes.html#container-recipes">singularity documentation</a>.</p>
<p>In order to build a singularity container from a singularity recipe file, you should use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">sudo singularity build &lt;NAME_CONTAINER&gt; &lt;YOUR_RECIPE_FILES&gt;</span>
</pre></div></div><div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>You always need to use sudo when you build a container from a recipe.</p>
</div>
</div>
<div class="section" id="build-recipe-on-singularity-hub">
<h4>Build recipe on singularity hub<a class="headerlink" href="#build-recipe-on-singularity-hub" title="Permalink to this headline">¶</a></h4>
<p>Singularity hub allows users to build containers from recipes directly on singularity-hub’s cloud meaning that you don’t need anymore to build containers by yourself.
You need to register on <a class="reference external" href="https://www.singularity-hub.org/">singularity-hub</a> and link your singularity-hub account to your github account, then</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Create a new github repository.</p></li>
<li><p>Add a collection on <a class="reference external" href="https://www.singularity-hub.org/">singularity-hub</a> and select the github repository your created.</p></li>
<li><p>Clone the github repository on your computer.</p></li>
<li><p>Write the singularity recipe and save it as a file nammed <strong>Singularity</strong>.</p></li>
<li><p>Git add <strong>Singularity</strong>, commit and push on the master branch.</p></li>
</ol>
</div></blockquote>
<p>At this point, robots from singularity-hub will build the container for you, you will be able to download your container from the website or directly with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">singularity pull shub://&lt;github_username&gt;/&lt;repository_name&gt;</span>
</pre></div></div></div>
<div class="section" id="example-recipe-with-openai-gym-mujoco-and-miniworld">
<h4>Example: Recipe with openai gym, mujoco and miniworld<a class="headerlink" href="#example-recipe-with-openai-gym-mujoco-and-miniworld" title="Permalink to this headline">¶</a></h4>
<p>Here is an example on how you can use singularity recipe to install complex environment as opanai gym, mujoco and miniworld on a pytorch based container.
In order to use mujoco, you’ll need to copy the key stored on the mila cluster in <cite>/ai/apps/mujoco/license/mjkey.txt</cite> to your current directory.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#This is a dockerfile that sets up a full Gym install with test dependencies</span>
Bootstrap: docker

<span class="c1"># Here we ll build our container upon the pytorch container</span>
From: pytorch/pytorch:1.0-cuda10.0-cudnn7-runtime

<span class="c1"># Now we&#39;ll copy the mjkey file located in the current directory inside the container&#39;s root</span>
<span class="c1"># directory</span>
%files
        mjkey.txt

<span class="c1"># Then we put everything we need to install</span>
%post
        <span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:/opt/conda/bin
        apt -y update <span class="o">&amp;&amp;</span> <span class="se">\</span>
        apt install -y keyboard-configuration <span class="o">&amp;&amp;</span> <span class="se">\</span>
        apt install -y <span class="se">\</span>
        python3-dev <span class="se">\</span>
        python-pyglet <span class="se">\</span>
        python3-opengl <span class="se">\</span>
        libhdf5-dev <span class="se">\</span>
        libjpeg-dev <span class="se">\</span>
        libboost-all-dev <span class="se">\</span>
        libsdl2-dev <span class="se">\</span>
        libosmesa6-dev <span class="se">\</span>
        patchelf <span class="se">\</span>
        ffmpeg <span class="se">\</span>
        xvfb <span class="se">\</span>
        libhdf5-dev <span class="se">\</span>
        openjdk-8-jdk <span class="se">\</span>
        wget <span class="se">\</span>
        git <span class="se">\</span>
        unzip <span class="o">&amp;&amp;</span> <span class="se">\</span>
        apt clean <span class="o">&amp;&amp;</span> <span class="se">\</span>
        rm -rf /var/lib/apt/lists/*
        pip install h5py

        <span class="c1"># Download Gym and Mujoco</span>
        mkdir /Gym <span class="o">&amp;&amp;</span> <span class="nb">cd</span> /Gym
        git clone https://github.com/openai/gym.git <span class="o">||</span> <span class="nb">true</span> <span class="o">&amp;&amp;</span> <span class="se">\</span>
        mkdir /Gym/.mujoco <span class="o">&amp;&amp;</span> <span class="nb">cd</span> /Gym/.mujoco
        wget https://www.roboti.us/download/mjpro150_linux.zip  <span class="o">&amp;&amp;</span> <span class="se">\</span>
        unzip mjpro150_linux.zip <span class="o">&amp;&amp;</span> <span class="se">\</span>
        wget https://www.roboti.us/download/mujoco200_linux.zip <span class="o">&amp;&amp;</span> <span class="se">\</span>
        unzip mujoco200_linux.zip <span class="o">&amp;&amp;</span> <span class="se">\</span>
        mv mujoco200_linux mujoco200

        <span class="c1"># Export global environment variables</span>
        <span class="nb">export</span> <span class="nv">MUJOCO_PY_MJKEY_PATH</span><span class="o">=</span>/Gym/.mujoco/mjkey.txt
        <span class="nb">export</span> <span class="nv">MUJOCO_PY_MUJOCO_PATH</span><span class="o">=</span>/Gym/.mujoco/mujoco150/
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/Gym/.mujoco/mjpro150/bin
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/Gym/.mujoco/mujoco200/bin
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/usr/local/bin
        cp /mjkey.txt /Gym/.mujoco/mjkey.txt
        <span class="c1"># Install python dependencies</span>
        wget https://raw.githubusercontent.com/openai/mujoco-py/master/requirements.txt
        pip install -r requirements.txt
        <span class="c1"># Install Gym and Mujoco</span>
        <span class="nb">cd</span> /Gym/gym
        pip install -e <span class="s1">&#39;.[all]&#39;</span>
        <span class="c1"># Change permission to use mujoco_py as non sudoer user</span>
        chmod -R <span class="m">777</span> /opt/conda/lib/python3.6/site-packages/mujoco_py/
        pip install --upgrade minerl

<span class="c1"># Export global environment variables</span>
%environment
        <span class="nb">export</span> <span class="nv">SHELL</span><span class="o">=</span>/bin/sh
        <span class="nb">export</span> <span class="nv">MUJOCO_PY_MJKEY_PATH</span><span class="o">=</span>/Gym/.mujoco/mjkey.txt
        <span class="nb">export</span> <span class="nv">MUJOCO_PY_MUJOCO_PATH</span><span class="o">=</span>/Gym/.mujoco/mujoco150/
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/Gym/.mujoco/mjpro150/bin
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/Gym/.mujoco/mujoco200/bin
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/usr/local/bin
        <span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span>/Gym/gym/.tox/py3/bin:<span class="nv">$PATH</span>

%runscript
        <span class="nb">exec</span> /bin/sh <span class="s2">&quot;</span><span class="nv">$@</span><span class="s2">&quot;</span>
</pre></div>
</div>
<p>Here is the same recipe but written for TensorFlow.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#This is a dockerfile that sets up a full Gym install with test dependencies</span>
Bootstrap: docker

<span class="c1"># Here we ll build our container upon the tensorflow container</span>
From: tensorflow/tensorflow:latest-gpu-py3

<span class="c1"># Now we&#39;ll copy the mjkey file located in the current directory inside the container&#39;s root</span>
<span class="c1"># directory</span>
%files
        mjkey.txt

<span class="c1"># Then we put everything we need to install</span>
%post
        apt -y update <span class="o">&amp;&amp;</span> <span class="se">\</span>
        apt install -y keyboard-configuration <span class="o">&amp;&amp;</span> <span class="se">\</span>
        apt install -y <span class="se">\</span>
        python3-setuptools <span class="se">\</span>
        python3-dev <span class="se">\</span>
        python-pyglet <span class="se">\</span>
        python3-opengl <span class="se">\</span>
        libjpeg-dev <span class="se">\</span>
        libboost-all-dev <span class="se">\</span>
        libsdl2-dev <span class="se">\</span>
        libosmesa6-dev <span class="se">\</span>
        patchelf <span class="se">\</span>
        ffmpeg <span class="se">\</span>
        xvfb <span class="se">\</span>
        wget <span class="se">\</span>
        git <span class="se">\</span>
        unzip <span class="o">&amp;&amp;</span> <span class="se">\</span>
        apt clean <span class="o">&amp;&amp;</span> <span class="se">\</span>
        rm -rf /var/lib/apt/lists/*

        <span class="c1"># Download Gym and Mujoco</span>
        mkdir /Gym <span class="o">&amp;&amp;</span> <span class="nb">cd</span> /Gym
        git clone https://github.com/openai/gym.git <span class="o">||</span> <span class="nb">true</span> <span class="o">&amp;&amp;</span> <span class="se">\</span>
        mkdir /Gym/.mujoco <span class="o">&amp;&amp;</span> <span class="nb">cd</span> /Gym/.mujoco
        wget https://www.roboti.us/download/mjpro150_linux.zip  <span class="o">&amp;&amp;</span> <span class="se">\</span>
        unzip mjpro150_linux.zip <span class="o">&amp;&amp;</span> <span class="se">\</span>
        wget https://www.roboti.us/download/mujoco200_linux.zip <span class="o">&amp;&amp;</span> <span class="se">\</span>
        unzip mujoco200_linux.zip <span class="o">&amp;&amp;</span> <span class="se">\</span>
        mv mujoco200_linux mujoco200

        <span class="c1"># Export global environment variables</span>
        <span class="nb">export</span> <span class="nv">MUJOCO_PY_MJKEY_PATH</span><span class="o">=</span>/Gym/.mujoco/mjkey.txt
        <span class="nb">export</span> <span class="nv">MUJOCO_PY_MUJOCO_PATH</span><span class="o">=</span>/Gym/.mujoco/mujoco150/
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/Gym/.mujoco/mjpro150/bin
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/Gym/.mujoco/mujoco200/bin
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/usr/local/bin
        cp /mjkey.txt /Gym/.mujoco/mjkey.txt

        <span class="c1"># Install python dependencies</span>
        wget https://raw.githubusercontent.com/openai/mujoco-py/master/requirements.txt
        pip install -r requirements.txt
        <span class="c1"># Install Gym and Mujoco</span>
        <span class="nb">cd</span> /Gym/gym
        pip install -e <span class="s1">&#39;.[all]&#39;</span>
        <span class="c1"># Change permission to use mujoco_py as non sudoer user</span>
        chmod -R <span class="m">777</span> /usr/local/lib/python3.5/dist-packages/mujoco_py/

        <span class="c1"># Then install miniworld</span>
        <span class="nb">cd</span> /usr/local/
        git clone https://github.com/maximecb/gym-miniworld.git
        <span class="nb">cd</span> gym-miniworld
        pip install -e .

<span class="c1"># Export global environment variables</span>
%environment
        <span class="nb">export</span> <span class="nv">SHELL</span><span class="o">=</span>/bin/bash
        <span class="nb">export</span> <span class="nv">MUJOCO_PY_MJKEY_PATH</span><span class="o">=</span>/Gym/.mujoco/mjkey.txt
        <span class="nb">export</span> <span class="nv">MUJOCO_PY_MUJOCO_PATH</span><span class="o">=</span>/Gym/.mujoco/mujoco150/
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/Gym/.mujoco/mjpro150/bin
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/Gym/.mujoco/mujoco200/bin
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:/usr/local/bin
        <span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span>/Gym/gym/.tox/py3/bin:<span class="nv">$PATH</span>

%runscript
        <span class="nb">exec</span> /bin/bash <span class="s2">&quot;</span><span class="nv">$@</span><span class="s2">&quot;</span>
</pre></div>
</div>
<p>Keep in mind that those environment variables are sourced at runtime and not at build time. This is why, you should also define them in the <code class="docutils literal notranslate"><span class="pre">%post</span></code> section since they are required to install mujuco.</p>
</div>
</div>
</div>
<div class="section" id="using-containers-on-clusters">
<h2><a class="toc-backref" href="#id8">Using containers on clusters</a><a class="headerlink" href="#using-containers-on-clusters" title="Permalink to this headline">¶</a></h2>
<p>On every cluster with SLURM, dataset and intermediate results should go in <code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code> while the final experiments results should go in <code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code>.
In order to use the container you built, you need to copy it on the cluster you want to use.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>You should always store your container in $SCRATCH !</p>
</div>
<p>Then reserve a node with srun/sbatch, copy the container and your dataset on the node given by slurm (i.e in <code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code>) and execute the code <code class="docutils literal notranslate"><span class="pre">&lt;YOUR_CODE&gt;</span></code> within the container <code class="docutils literal notranslate"><span class="pre">&lt;YOUR_CONTAINER&gt;</span></code> with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">singularity <span class="nb">exec</span> --nv -H <span class="nv">$HOME</span>:/home -B <span class="nv">$SLURM_TMPDIR</span>:/dataset/ -B <span class="nv">$SLURM_TMPDIR</span>:/tmp_log/ -B <span class="nv">$SCRATCH</span>:/final_log/ <span class="nv">$SLURM_TMPDIR</span>/&lt;YOUR_CONTAINER&gt; python &lt;YOUR_CODE&gt;</span>
</pre></div></div><p>Remember that <code class="docutils literal notranslate"><span class="pre">/dataset</span></code>, <code class="docutils literal notranslate"><span class="pre">/tmp_log</span></code> and <code class="docutils literal notranslate"><span class="pre">/final_log</span></code> were created in the previous section. Now each time, we’ll use singularity, we are
explicitly telling it to mount <code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code> on the cluster’s node in the folder <code class="docutils literal notranslate"><span class="pre">/dataset</span></code> inside the container with the option <code class="docutils literal notranslate"><span class="pre">-B</span></code> such that
each dataset downloaded by pytorch in <code class="docutils literal notranslate"><span class="pre">/dataset</span></code> will be available in <code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code>.</p>
<p>This will allow us to have code and scripts that are invariant to the cluster environment. The option <code class="docutils literal notranslate"><span class="pre">-H</span></code> specify what will be the container’s home. For example,
if you have your code in <code class="docutils literal notranslate"><span class="pre">$HOME/Project12345/Version35/</span></code> you can specify <code class="docutils literal notranslate"><span class="pre">-H</span> <span class="pre">$HOME/Project12345/Version35:/home</span></code>, thus the container will only have access to
the code inside <code class="docutils literal notranslate"><span class="pre">Version35</span></code>.</p>
<p>If you want to run multiple commands inside the container you can use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">singularity <span class="nb">exec</span> --nv -H <span class="nv">$HOME</span>:/home -B <span class="nv">$SLURM_TMPDIR</span>:/dataset/ -B <span class="nv">$SLURM_TMPDIR</span>:/tmp_log/ -B <span class="nv">$SCRATCH</span>:/final_log/ <span class="nv">$SLURM_TMPDIR</span>/&lt;YOUR_CONTAINER&gt; bash -c <span class="s1">&#39;pwd &amp;&amp; ls &amp;&amp; python &lt;YOUR_CODE&gt;&#39;</span></span>
</pre></div></div><div class="section" id="example-interactive-case-srun-salloc">
<h3><a class="toc-backref" href="#id9">Example: Interactive case (srun/salloc)</a><a class="headerlink" href="#example-interactive-case-srun-salloc" title="Permalink to this headline">¶</a></h3>
<p>Once you get an interactive session with slurm, copy <code class="docutils literal notranslate"><span class="pre">&lt;YOUR_CONTAINER&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;YOUR_DATASET&gt;</span></code> to <code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><style type="text/css">
span.prompt3:before {
  content: "# ";
}
</style><span class="prompt3"><span class="m">0</span>. Get an interactive session</span>
<span class="prompt1">srun --gres<span class="o">=</span>gpu:1</span>
<span class="prompt3"><span class="m">1</span>. Copy your container on the compute node</span>
<span class="prompt1">rsync -avz <span class="nv">$SCRATCH</span>/&lt;YOUR_CONTAINER&gt; <span class="nv">$SLURM_TMPDIR</span></span>
<span class="prompt3"><span class="m">2</span>. Copy your dataset on the compute node</span>
<span class="prompt1">rsync -avz <span class="nv">$SCRATCH</span>/&lt;YOUR_DATASET&gt; <span class="nv">$SLURM_TMPDIR</span></span>
</pre></div></div><p>then use <code class="docutils literal notranslate"><span class="pre">singularity</span> <span class="pre">shell</span></code> to get a shell inside the container</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt3"><span class="m">3</span>. Get a shell <span class="k">in</span> your environment</span>
<span class="prompt1">singularity shell --nv <span class="se">\</span>
        -H <span class="nv">$HOME</span>:/home <span class="se">\</span>
        -B <span class="nv">$SLURM_TMPDIR</span>:/dataset/ <span class="se">\</span>
        -B <span class="nv">$SLURM_TMPDIR</span>:/tmp_log/ <span class="se">\</span>
        -B <span class="nv">$SCRATCH</span>:/final_log/ <span class="se">\</span>
        <span class="nv">$SLURM_TMPDIR</span>/&lt;YOUR_CONTAINER&gt;</span>
</pre></div></div><div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt3"><span class="m">4</span>. Execute your code</span>
<span class="prompt2">python &lt;YOUR_CODE&gt;</span>
</pre></div></div><p><strong>or</strong> use <code class="docutils literal notranslate"><span class="pre">singularity</span> <span class="pre">exec</span></code> to execute <code class="docutils literal notranslate"><span class="pre">&lt;YOUR_CODE&gt;</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt3"><span class="m">3</span>. Execute your code</span>
<span class="prompt1">singularity <span class="nb">exec</span> --nv <span class="se">\</span>
        -H <span class="nv">$HOME</span>:/home <span class="se">\</span>
        -B <span class="nv">$SLURM_TMPDIR</span>:/dataset/ <span class="se">\</span>
        -B <span class="nv">$SLURM_TMPDIR</span>:/tmp_log/ <span class="se">\</span>
        -B <span class="nv">$SCRATCH</span>:/final_log/ <span class="se">\</span>
        <span class="nv">$SLURM_TMPDIR</span>/&lt;YOUR_CONTAINER&gt; <span class="se">\</span>
        python &lt;YOUR_CODE&gt;</span>
</pre></div></div><p>You can create also the following alias to make your life easier.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1"><span class="nb">alias</span> <span class="nv">my_env</span><span class="o">=</span><span class="s1">&#39;singularity exec --nv \</span>
<span class="s1">        -H $HOME:/home \</span>
<span class="s1">        -B $SLURM_TMPDIR:/dataset/ \</span>
<span class="s1">        -B $SLURM_TMPDIR:/tmp_log/ \</span>
<span class="s1">        -B $SCRATCH:/final_log/ \</span>
<span class="s1">        $SLURM_TMPDIR/&lt;YOUR_CONTAINER&gt;&#39;</span></span>
</pre></div></div><p>This will allow you to run any code with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">my_env python &lt;YOUR_CODE&gt;</span>
</pre></div></div></div>
<div class="section" id="example-sbatch-case">
<h3><a class="toc-backref" href="#id10">Example: sbatch case</a><a class="headerlink" href="#example-sbatch-case" title="Permalink to this headline">¶</a></h3>
<p>You can also create a <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> script:</p>
<div class="highlight-bash notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --cpus-per-task=6         # Ask for 6 CPUs</span>
<span class="c1">#SBATCH --gres=gpu:1              # Ask for 1 GPU</span>
<span class="c1">#SBATCH --mem=10G                 # Ask for 10 GB of RAM</span>
<span class="c1">#SBATCH --time=0:10:00            # The job will run for 10 minutes</span>

<span class="c1"># 1. Copy your container on the compute node</span>
rsync -avz <span class="nv">$SCRATCH</span>/&lt;YOUR_CONTAINER&gt; <span class="nv">$SLURM_TMPDIR</span>
<span class="c1"># 2. Copy your dataset on the compute node</span>
rsync -avz <span class="nv">$SCRATCH</span>/&lt;YOUR_DATASET&gt; <span class="nv">$SLURM_TMPDIR</span>
<span class="c1"># 3. Executing your code with singularity</span>
singularity <span class="nb">exec</span> --nv <span class="se">\</span>
        -H <span class="nv">$HOME</span>:/home <span class="se">\</span>
        -B <span class="nv">$SLURM_TMPDIR</span>:/dataset/ <span class="se">\</span>
        -B <span class="nv">$SLURM_TMPDIR</span>:/tmp_log/ <span class="se">\</span>
        -B <span class="nv">$SCRATCH</span>:/final_log/ <span class="se">\</span>
        <span class="nv">$SLURM_TMPDIR</span>/&lt;YOUR_CONTAINER&gt; <span class="se">\</span>
        python &lt;YOUR_CODE&gt;
<span class="c1"># 4. Copy whatever you want to save on $SCRATCH</span>
rsync -avz <span class="nv">$SLURM_TMPDIR</span>/&lt;to_save&gt; <span class="nv">$SCRATCH</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="issue-with-pybullet-and-opengl-libraries">
<h3><a class="toc-backref" href="#id11">Issue with PyBullet and OpenGL libraries</a><a class="headerlink" href="#issue-with-pybullet-and-opengl-libraries" title="Permalink to this headline">¶</a></h3>
<p>If you are running certain gym environments that require <code class="docutils literal notranslate"><span class="pre">pyglet</span></code>, you may encounter a problem when running your singularity instance with the Nvidia drivers using the <code class="docutils literal notranslate"><span class="pre">--nv</span></code> flag. This happens because the <code class="docutils literal notranslate"><span class="pre">--nv</span></code> flag also provides the OpenGL libraries:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>libGL.so.1 <span class="o">=</span>&gt; /.singularity.d/libs/libGL.so.1
libGLX.so.0 <span class="o">=</span>&gt; /.singularity.d/libs/libGLX.so.0
</pre></div>
</div>
<p>If you don’t experience those problems with <code class="docutils literal notranslate"><span class="pre">pyglet</span></code>, you probably don’t need to address this. Otherwise, you can resolve those problems by <code class="docutils literal notranslate"><span class="pre">apt-get</span> <span class="pre">install</span> <span class="pre">-y</span> <span class="pre">libosmesa6-dev</span> <span class="pre">mesa-utils</span> <span class="pre">mesa-utils-extra</span> <span class="pre">libgl1-mesa-glx</span></code>, and then making sure that your <code class="docutils literal notranslate"><span class="pre">LD_LIBRARY_PATH</span></code> points to those libraries before the ones in <code class="docutils literal notranslate"><span class="pre">/.singularity.d/libs</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%environment
        <span class="c1"># ...</span>
        <span class="nb">export</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span>/usr/lib/x86_64-linux-gnu/mesa:<span class="nv">$LD_LIBRARY_PATH</span>
</pre></div>
</div>
</div>
<div class="section" id="id3">
<h3><a class="toc-backref" href="#id12">Mila cluster</a><a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>On the Mila cluster <code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code> is not yet defined, you should add the experiment results you want to keep in <code class="docutils literal notranslate"><span class="pre">/network/tmp1/$USER/</span></code>.
In order to use the sbatch script above and to match other cluster environment’s names, you can define <code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code> as an alias for <code class="docutils literal notranslate"><span class="pre">/network/tmp1/$USER</span></code> with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1"><span class="nb">echo</span> <span class="s2">&quot;export SCRATCH=/network/tmp1/</span><span class="nv">$USER</span><span class="s2">&quot;</span> &gt;&gt; ~/.bashrc</span>
</pre></div></div><p>Then, you can follow the general procedure explained above.</p>
</div>
<div class="section" id="mila-cloud-cluster">
<h3><a class="toc-backref" href="#id13">Mila-cloud cluster</a><a class="headerlink" href="#mila-cloud-cluster" title="Permalink to this headline">¶</a></h3>
<p>On mila-cloud, the procedure is the same as above except that you have to define <code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code> as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1"><span class="nb">echo</span> <span class="s2">&quot;export SCRATCH=/scratch/</span><span class="nv">$USER</span><span class="s2">&quot;</span> &gt;&gt; ~/.bashrc</span>
</pre></div></div></div>
<div class="section" id="compute-canada">
<h3><a class="toc-backref" href="#id14">Compute Canada</a><a class="headerlink" href="#compute-canada" title="Permalink to this headline">¶</a></h3>
<p>Using singularity on Compute Canada is similar except that you need to add Yoshua’s account name and load singularity.
Here is an example of a <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> script using singularity on compute Canada cluster:</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>You should use singularity/2.6 or singularity/3.4. There is a bug in singularity/3.2 which makes gpu unusable.</p>
</div>
<div class="highlight-bash notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --account=rpp-bengioy     # Yoshua pays for your job</span>
<span class="c1">#SBATCH --cpus-per-task=6         # Ask for 6 CPUs</span>
<span class="c1">#SBATCH --gres=gpu:1              # Ask for 1 GPU</span>
<span class="c1">#SBATCH --mem=32G                 # Ask for 32 GB of RAM</span>
<span class="c1">#SBATCH --time=0:10:00            # The job will run for 10 minutes</span>
<span class="c1">#SBATCH --output=&quot;/scratch/&lt;user&gt;/slurm-%j.out&quot; # Modify the output of sbatch</span>

<span class="c1"># 1. You have to load singularity</span>
module load singularity
<span class="c1"># 2. Then you copy the container to the local disk</span>
rsync -avz <span class="nv">$SCRATCH</span>/&lt;YOUR_CONTAINER&gt; <span class="nv">$SLURM_TMPDIR</span>
<span class="c1"># 3. Copy your dataset on the compute node</span>
rsync -avz <span class="nv">$SCRATCH</span>/&lt;YOUR_DATASET&gt; <span class="nv">$SLURM_TMPDIR</span>
<span class="c1"># 4. Executing your code with singularity</span>
singularity <span class="nb">exec</span> --nv <span class="se">\</span>
        -H <span class="nv">$HOME</span>:/home <span class="se">\</span>
        -B <span class="nv">$SLURM_TMPDIR</span>:/dataset/ <span class="se">\</span>
        -B <span class="nv">$SLURM_TMPDIR</span>:/tmp_log/ <span class="se">\</span>
        -B <span class="nv">$SCRATCH</span>:/final_log/ <span class="se">\</span>
        <span class="nv">$SLURM_TMPDIR</span>/&lt;YOUR_CONTAINER&gt; <span class="se">\</span>
        python &lt;YOUR_CODE&gt;
<span class="c1"># 5. Copy whatever you want to save on $SCRATCH</span>
rsync -avz <span class="nv">$SLURM_TMPDIR</span>/&lt;to_save&gt; <span class="nv">$SCRATCH</span>
</pre></div>
</td></tr></table></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="../docker/index.html" class="btn btn-neutral" title="Docker/Shifter" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> and ❤️  using a custom <a href="https://github.com/LinxiFan/Sphinx-theme">theme</a> based on <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'latest',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/language_data.js"></script>
      <script type="text/javascript" src="../_static/clipboard.min.js"></script>
      <script type="text/javascript" src="../_static/copybutton.js"></script>
      <script type="text/javascript" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/documentation_options_fix.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>